{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kn0wthing/practice/blob/main/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CYG3mZUKSJf",
        "outputId": "10ce6f38-5c1d-4d4b-db21-e912f988fbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6scNEqlfMagF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "kaggle_dir = '/root/.kaggle'\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1aIg8UrMetl",
        "outputId": "6f21ed10-234c-4374-dc49-1de065a089e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rAqisrGTMkLr"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json {kaggle_dir}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rHQ0C6yaNBN9"
      },
      "outputs": [],
      "source": [
        "!chmod 600 {kaggle_dir}/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I5AJ6AANPj5",
        "outputId": "9bf2e58e-19b8-4b2f-bbec-66886a45bd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "quora-insincere-questions-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oOxXGFcyNiIM"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/quora-insincere-questions-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pM4pZolxOWgi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pLQbXYD0u0L3"
      },
      "outputs": [],
      "source": [
        "class MyDataLoader:\n",
        "    \"\"\"\n",
        "    A class for loading and preprocessing the dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, train_path: str):\n",
        "        self.train_path = train_path\n",
        "        self.data = None\n",
        "        self.X_train = None\n",
        "        self.X_val = None\n",
        "        self.y_train = None\n",
        "        self.y_val = None\n",
        "\n",
        "    def load_data(self) -> pd.DataFrame:\n",
        "        self.data = pd.read_csv(self.train_path)\n",
        "        self.data = self.data[['question_text', 'target']].dropna()\n",
        "        return self.data\n",
        "\n",
        "    def split_data(self, test_size: float = 0.2, random_state: int = 42):\n",
        "        if self.data is None:\n",
        "            self.load_data()\n",
        "        X = self.data['question_text'].values\n",
        "        y = self.data['target'].values\n",
        "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "        print(f\"Data split: {len(self.X_train)} training samples, {len(self.X_val)} validation samples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2o1AATIqu0Ii"
      },
      "outputs": [],
      "source": [
        "class TextPreprocessor:\n",
        "    \"\"\"\n",
        "    A class for preprocessing text data.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_words: int = 100000, max_len: int = 100):\n",
        "        self.max_words = max_words\n",
        "        self.max_len = max_len\n",
        "        self.word_index = {'<PAD>': 0, '<UNK>': 1}  # Special tokens for padding and unknown words\n",
        "        self.index_word = {0: '<PAD>', 1: '<UNK>'}\n",
        "        self.vocab_size = 2  # Initialize with special tokens count\n",
        "\n",
        "    def build_vocab(self, texts: np.ndarray):\n",
        "        word_freq = {}\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            for word in words:\n",
        "                word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "        # Sort words by frequency and take the most common words up to max_words\n",
        "        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:(self.max_words - 2)]\n",
        "        for i, (word, freq) in enumerate(sorted_words, start=2):\n",
        "            self.word_index[word] = i\n",
        "            self.index_word[i] = word\n",
        "        self.vocab_size = len(self.word_index)\n",
        "        print(f\"Vocabulary built. Size: {self.vocab_size}\")\n",
        "\n",
        "    def texts_to_sequences(self, texts: np.ndarray) -> list:\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            words = text.split()\n",
        "            seq = [self.word_index.get(word, 1) for word in words]  # 1 is the index for <UNK>\n",
        "            sequences.append(seq)\n",
        "        return sequences\n",
        "\n",
        "    def pad_sequences(self, sequences: list) -> np.ndarray:\n",
        "        padded_sequences = np.zeros((len(sequences), self.max_len), dtype=int)\n",
        "        for i, seq in enumerate(sequences):\n",
        "            seq = seq[:self.max_len]  # Truncate if longer than max_len\n",
        "            padded_sequences[i, :len(seq)] = seq\n",
        "        return padded_sequences\n",
        "\n",
        "    def transform_text(self, texts: np.ndarray) -> np.ndarray:\n",
        "        sequences = self.texts_to_sequences(texts)\n",
        "        padded_sequences = self.pad_sequences(sequences)\n",
        "        return padded_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XdLdx52Yu0GP"
      },
      "outputs": [],
      "source": [
        "class QuoraDataset(Dataset):\n",
        "    def __init__(self, sequences: np.ndarray, labels: np.ndarray):\n",
        "        self.sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.sequences[idx], self.labels[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z9lrU6anu0Dh"
      },
      "outputs": [],
      "source": [
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, vocabulary_size: int, embedding_dim: int = 128, lstm_units: int = 64, dropout_rate: float = 0.3):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_units, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc1 = nn.Linear(lstm_units * 2, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)  # (batch_size, max_len, embedding_dim)\n",
        "        lstm_out, _ = self.lstm(embedded)  # (batch_size, max_len, lstm_units*2)\n",
        "        # We can take the last hidden state for classification, or use the mean of the outputs:\n",
        "        out = lstm_out[:, -1, :]  # (batch_size, lstm_units*2)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TVpWC49Zu0BF"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \"\"\"\n",
        "    A class for training the model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model: nn.Module, learning_rate: float = 0.001, batch_size: int = 128, epochs: int = 10, patience: int = 3):\n",
        "        self.model = model\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.patience = patience\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model.to(self.device)\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.best_model_state = None\n",
        "        self.no_improvement_count = 0\n",
        "\n",
        "    def train(self, train_dataset: Dataset, val_dataset: Dataset):\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        print(\"Starting training...\")\n",
        "        for epoch in range(self.epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for sequences, labels in train_loader:\n",
        "                sequences, labels = sequences.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                predictions = self.model(sequences)\n",
        "                loss = self.criterion(predictions, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            val_loss = self.validate(val_loader)\n",
        "            print(f\"Epoch {epoch+1}/{self.epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "            # Early stopping and checkpointing\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.best_model_state = self.model.state_dict()\n",
        "                self.no_improvement_count = 0\n",
        "                print(\"Validation loss improved. Model checkpoint saved.\")\n",
        "            else:\n",
        "                self.no_improvement_count += 1\n",
        "                if self.no_improvement_count >= self.patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        # Load the best model state\n",
        "        if self.best_model_state is not None:\n",
        "            self.model.load_state_dict(self.best_model_state)\n",
        "        print(\"Training completed.\")\n",
        "\n",
        "    def validate(self, val_loader: DataLoader) -> float:\n",
        "        self.model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for sequences, labels in val_loader:\n",
        "                sequences, labels = sequences.to(self.device), labels.to(self.device)\n",
        "                predictions = self.model(sequences)\n",
        "                loss = self.criterion(predictions, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "        return val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sQh_iHbSuz-f"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def evaluate(self, model: nn.Module, val_dataset: Dataset):\n",
        "        model.eval()\n",
        "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        with torch.no_grad():\n",
        "            for sequences, labels in val_loader:\n",
        "                sequences = sequences.to(self.device)\n",
        "                predictions = model(sequences)\n",
        "                preds = (predictions > 0.5).cpu().numpy().astype(\"int32\")\n",
        "                all_preds.extend(preds)\n",
        "                all_labels.extend(labels.numpy().astype(\"int32\"))\n",
        "\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        prec = precision_score(all_labels, all_preds)\n",
        "        rec = recall_score(all_labels, all_preds)\n",
        "        f1 = f1_score(all_labels, all_preds)\n",
        "        cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "        print(\"Evaluation Results:\")\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print(f\"Precision: {prec:.4f}\")\n",
        "        print(f\"Recall: {rec:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eS3ZScTquz73"
      },
      "outputs": [],
      "source": [
        "class Predictor:\n",
        "    def __init__(self, model: nn.Module, preprocessor: TextPreprocessor):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.preprocessor = preprocessor\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    def predict(self, questions: list) -> list:\n",
        "        sequences = self.preprocessor.transform_text(np.array(questions))\n",
        "        sequences = torch.tensor(sequences, dtype=torch.long).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(sequences)\n",
        "            predictions = (predictions > 0.5).cpu().numpy().astype(\"int32\")\n",
        "        return predictions.ravel().tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaJqwBHSuz5O",
        "outputId": "7fcebfb8-aa89-4b9c-c273-727efa5b8ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split: 1044897 training samples, 261225 validation samples.\n",
            "Vocabulary built. Size: 100000\n",
            "Starting training...\n",
            "Epoch 1/10, Training Loss: 0.2370, Validation Loss: 0.2290\n",
            "Validation loss improved. Model checkpoint saved.\n",
            "Epoch 2/10, Training Loss: 0.2343, Validation Loss: 0.2290\n",
            "Validation loss improved. Model checkpoint saved.\n",
            "Epoch 3/10, Training Loss: 0.2335, Validation Loss: 0.2289\n",
            "Validation loss improved. Model checkpoint saved.\n",
            "Epoch 4/10, Training Loss: 0.2332, Validation Loss: 0.2289\n",
            "Epoch 5/10, Training Loss: 0.2331, Validation Loss: 0.2290\n",
            "Epoch 6/10, Training Loss: 0.2330, Validation Loss: 0.2289\n",
            "Early stopping triggered.\n",
            "Training completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Data Loading and Splitting\n",
        "data_loader = MyDataLoader(train_path='train.csv')\n",
        "data = data_loader.load_data()\n",
        "data_loader.split_data()\n",
        "\n",
        "# Step 2: Text Preprocessing\n",
        "text_preprocessor = TextPreprocessor(max_words=100000, max_len=200)\n",
        "text_preprocessor.build_vocab(data_loader.X_train)\n",
        "X_train_seq = text_preprocessor.transform_text(data_loader.X_train)\n",
        "X_val_seq = text_preprocessor.transform_text(data_loader.X_val)\n",
        "\n",
        "# Convert data to PyTorch datasets\n",
        "train_dataset = QuoraDataset(X_train_seq, data_loader.y_train)\n",
        "val_dataset = QuoraDataset(X_val_seq, data_loader.y_val)\n",
        "\n",
        "# Step 3: Model Building\n",
        "bilstm_model = BiLSTMModel(\n",
        "    vocabulary_size=text_preprocessor.vocab_size,\n",
        "    embedding_dim=128,\n",
        "    lstm_units=64,\n",
        "    dropout_rate=0.3,\n",
        ")\n",
        "\n",
        "# Step 4: Model Training\n",
        "trainer = Trainer(model=bilstm_model, learning_rate=0.001, batch_size=128, epochs=10, patience=3)\n",
        "trainer.train(train_dataset, val_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bHJNP9Dduz2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cd1d7a-4cb3-4dbe-e934-e9dd18647fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results:\n",
            "Accuracy: 0.9393\n",
            "Precision: 0.0000\n",
            "Recall: 0.0000\n",
            "F1 Score: 0.0000\n",
            "Confusion Matrix:\n",
            "[[245369      0]\n",
            " [ 15856      0]]\n",
            "Question: Why do people ask insincere questions on Quora? -> Prediction: Sincere\n",
            "Question: How to lose weight quickly? -> Prediction: Sincere\n"
          ]
        }
      ],
      "source": [
        "# # Step 5: Model Evaluation\n",
        "evaluator = Evaluator()\n",
        "evaluator.evaluate(bilstm_model, val_dataset)\n",
        "\n",
        "# Step 6: Inference (Prediction)\n",
        "predictor = Predictor(model=bilstm_model, preprocessor=text_preprocessor)\n",
        "sample_questions = [\n",
        "    \"Why do people ask insincere questions on Quora?\",\n",
        "    \"How to lose weight quickly?\"\n",
        "]\n",
        "predictions = predictor.predict(sample_questions)\n",
        "for question, prediction in zip(sample_questions, predictions):\n",
        "    print(f\"Question: {question} -> Prediction: {'Insincere' if prediction == 1 else 'Sincere'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DqUkKDNSlYao"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWXW1pjXh7FBaCalfKs6Wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}